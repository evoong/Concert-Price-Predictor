{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from googlesearch import search\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from requests import get\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium_recaptcha import Recaptcha_Solver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import requests\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../Documents/Ticket Sales.xlsx\"\n",
    "events = pd.read_excel(path, sheet_name =\"Events\")\n",
    "socials = pd.read_excel(path, sheet_name =\"Socials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options =  webdriver.ChromeOptions()\n",
    "options.add_argument(\"user-data-dir=C:\\\\Users\\\\eric9\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\\Default\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_to_number(s):\n",
    "    s = s.lower().strip()\n",
    "    # Handle comma-separated numbers\n",
    "    if ',' in s:\n",
    "        return int(s.replace(',', ''))\n",
    "    # Handle suffixes like K, M, B\n",
    "    elif 'k' in s:\n",
    "        return int(float(s.replace('k', '')) * 1000)\n",
    "    elif 'm' in s:\n",
    "        return int(float(s.replace('m', '')) * 1000000)\n",
    "    elif 'b' in s:\n",
    "        return int(float(s.replace('b', '')) * 1000000000)\n",
    "    else:\n",
    "        return int(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Search and Web Scraping with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a Google search using Selenium\n",
    "def get_first_search_result(query):\n",
    "    driver.get(f\"https://www.google.com/search?q={query}\")\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    first_result = soup.find('div', class_='g')\n",
    "    if first_result:\n",
    "        first_link = first_result.find('a')['href']\n",
    "        return first_link\n",
    "    \n",
    "    driver.get(f\"https://www.bing.com/search?q={query}\")\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    first_result = soup.find('li', class_='b_algo')\n",
    "    if first_result:\n",
    "        if 'href' in first_result.find('a').attrs:\n",
    "            first_link = first_result.find('a')['href']\n",
    "            return first_link\n",
    "    \n",
    "    try:\n",
    "        results = list(search(query, advanced=True, num_results=1))\n",
    "        if len(results) != 0:\n",
    "            return results[0].url\n",
    "    except:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstagramProfile:\n",
    "    def __init__(self, artist, username =None, follower_count = 0):\n",
    "        self.artist = artist\n",
    "        self.username = username\n",
    "        self.follower_count = follower_count\n",
    "\n",
    "    def get_username(self):\n",
    "        if self.username:\n",
    "            pass \n",
    "        driver.get(\"https://www.instagram.com/web/search/topsearch/?query=\" + self.artist)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        pre_tag = soup.find('pre')\n",
    "        if pre_tag is not None:\n",
    "            json_data = json.loads(pre_tag.text)\n",
    "            users = json_data['users']\n",
    "            if len(users) != 0:\n",
    "                self.username = users[0]['user']['username']\n",
    "        if pd.isna(self.username):\n",
    "            self.get_username2()\n",
    "        \n",
    "    def get_username2(self):\n",
    "        url = get_first_search_result((\"instagram profile \" + self.artist))\n",
    "        if url:\n",
    "            match = re.search(r'instagram\\.com/([^/?]+)', url)\n",
    "            if match:\n",
    "                self.username = match.group(1)\n",
    "\n",
    "\n",
    "    def get_followers(self):\n",
    "        if self.username is None:\n",
    "            self.follower_count = 0\n",
    "        url = \"https://www.instagram.com/\" +  str(self.username)\n",
    "        page = get(url, timeout=5)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        data = soup.find_all('meta', attrs={'property': 'og:description'})\n",
    "        if len(data) == 0:\n",
    "            driver.get(url)\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            data = soup.find_all('meta', attrs={'property': 'og:description'}\n",
    "                                 )\n",
    "        if len(data) == 0:\n",
    "            self.follower_count = 0\n",
    "        else:\n",
    "            follower_count = data[0].get('content').split()[0]\n",
    "            self.follower_count = convert_string_to_number(follower_count)    \n",
    "         \n",
    "    \n",
    "    def get_all(self):\n",
    "        self.get_username()\n",
    "        self.get_followers()\n",
    "        return self.username, self.follower_count\n",
    "    def __str__(self):\n",
    "        return f\"Artist: {self.artist}\\nInstagram Username: {self.username}\\nFollowers: {self.follower_count}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterProfile:\n",
    "    def __init__(self, artist, username = None, follower_count = 0):\n",
    "        self.artist = artist\n",
    "        self.username = username\n",
    "        self.follower_count = follower_count\n",
    "    \n",
    "    def get_username(self):\n",
    "        if (self.username):\n",
    "            pass\n",
    "        driver.get(f\"https://x.com/search?q={self.artist}&f=user\")\n",
    "        try:\n",
    "            WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, \"//div[@aria-label='Timeline: Search timeline']\")))\n",
    "            search_result = driver.find_element(By.XPATH, \"//div[@aria-label='Timeline: Search timeline']\")\n",
    "            link_element = search_result.find_elements(By.XPATH, \"//a[@tabindex='-1' and @role='link']\")\n",
    "            href = link_element[1].get_attribute('href')\n",
    "            self.username = re.search(r'x\\.com/([^/?]+)', href).group(1)\n",
    "        except Exception as e:\n",
    "            self.get_username2()\n",
    "            pass\n",
    "    \n",
    "    def get_username2(self):\n",
    "        url = get_first_search_result(\"twitter account \" + self.artist)\n",
    "        if url:\n",
    "            match = re.search(r'twitter\\.com/([^/?]+)', url)\n",
    "            if match:\n",
    "                self.username = match.group(1)\n",
    "\n",
    "\n",
    "    def get_followers(self):\n",
    "        if not pd.isna(self.username):\n",
    "            url = \"https://www.x.com/\" + str(self.username)\n",
    "            driver.get(url)\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            # Wait for the follower element to be present\n",
    "            followers_xpath = '//a[contains(@href, \"/verified_followers\") and @dir=\"ltr\" and @role=\"link\"]'\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, followers_xpath)))\n",
    "                follower_element = driver.find_element(By.XPATH, followers_xpath)\n",
    "                follower_element_text = follower_element.text.replace(' Followers', '')\n",
    "                follower_count = convert_string_to_number(follower_element_text)\n",
    "                self.follower_count = follower_count\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    def get_all(self):\n",
    "        self.get_username()\n",
    "        self.get_followers()\n",
    "        if self.follower_count < 1000:\n",
    "            self.get_username2()\n",
    "            self.get_followers()\n",
    "        return self.username, self.follower_count\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Artist: {self.artist}\\nTwitter Username: {self.username}\\nFollowers: {self.follower_count}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access token: BQD2nfHRNnj_CJhGNTlfTqX-pnD6faHbJhOOMG55f8bqHiEeRcJ-k7kgA87G1Vsgl8rGy6UwBhCdFtU0D9Pg-lOGNOuySYdlZFgJ1p5EjG_tjWhXHbc\n"
     ]
    }
   ],
   "source": [
    "from http import client\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "with open(\"../spotify_credentials.json\", \"r\") as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "client_id = credentials[\"client_id\"]\n",
    "client_secret = credentials[\"client_secret\"]\n",
    "auth_url = credentials[\"auth_url\"]\n",
    "response = requests.post(\n",
    "    auth_url,\n",
    "    headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n",
    "    data={\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": client_id,\n",
    "        \"client_secret\": client_secret\n",
    "    }\n",
    ")\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    token_info = response.json()\n",
    "    access_token = token_info['access_token']\n",
    "    print(\"Access token:\", access_token)\n",
    "else:\n",
    "    print(\"Failed to retrieve access token:\", response.status_code, response.text)\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\"\n",
    "}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SpotifyProfile:\n",
    "    def __init__(self, artist, spotifyID = None, genre = None, followers = 0, popularity = 0, listens = 0):\n",
    "        self.artist = artist\n",
    "        self.spotifyID = spotifyID\n",
    "        self.genre = genre\n",
    "        self.followers = followers\n",
    "        self.popularity = popularity\n",
    "        self.listens = listens\n",
    "        self.url = None\n",
    "\n",
    "    def get_id(self):\n",
    "        if self.spotifyID:\n",
    "            return self.spotifyID\n",
    "        search_url = f\"https://api.spotify.com/v1/search?q=artist:{self.artist}&type=artist&limit=1\"\n",
    "        response = requests.get(search_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            search_results = response.json()\n",
    "            if len(search_results['artists']['items']):\n",
    "                self.spotifyID = search_results['artists']['items'][0]['id']\n",
    "        if self.spotifyID is None:\n",
    "            self.get_id2()\n",
    "\n",
    "    \n",
    "    def get_id2(self):\n",
    "        url = get_first_search_result(\"spotify  \" + self.artist)\n",
    "        if url:\n",
    "            match = re.search(r'artist/([^/?]+)', url)\n",
    "            if match:\n",
    "                self.spotifyID = match.group(1)\n",
    "\n",
    "    def get_spot_stats(self):\n",
    "        search_url = f\"https://api.spotify.com/v1/artists/{self.spotifyID}\"\n",
    "        response = requests.get(search_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            self.spotifyID = result['id']\n",
    "            if len(result['genres']):\n",
    "                self.genre = result['genres'][0]\n",
    "            self.followers = result['followers']['total']\n",
    "            self.popularity = result['popularity']\n",
    "            self.url = result['external_urls']['spotify']\n",
    "            \n",
    "    def get_listens(self,):\n",
    "        if self.url is None:\n",
    "            return None\n",
    "        response = requests.get(self.url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        meta_tag = soup.find('meta', attrs={'property': 'og:description'})\n",
    "        if meta_tag:\n",
    "            content = meta_tag.get('content')\n",
    "            match = re.search(r'(\\d+(\\.\\d+)?[MK]?) monthly listeners', content)\n",
    "            if match:\n",
    "                self.listens = convert_string_to_number(match.group(1))\n",
    "\n",
    "    def get_all(self):\n",
    "        self.get_id()\n",
    "        self.get_spot_stats()\n",
    "        self.get_listens()\n",
    "        if self.listens <90000:\n",
    "            self.get_id2()\n",
    "            self.get_spot_stats()\n",
    "            self.get_listens()\n",
    "        return self.spotifyID, self.genre, self.followers, self.popularity, self.listens\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Artist: {self.artist}\\nSpotify ID: {self.spotifyID}\\nGenre: {self.genre}\\nFollowers: {self.followers}\\nPopularity: {self.popularity}\\nMonthly Listeners: {self.listens}\"\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# search_query = \"genre:edm\"\n",
    "# search_type = \"artist\"\n",
    "# search_url = f\"https://api.spotify.com/v1/search?q={search_query}&type={search_type}\"\n",
    "\n",
    "# response = requests.get(search_url, headers=headers)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     search_results = response.json()\n",
    "#     # print(json.dumps(search_results, indent=4))\n",
    "# else:\n",
    "#     print(\"Failed to retrieve search results:\", response.status_code, response.text)\n",
    "# # print(search_results['artists']['items'][0]['followers']['total'])\n",
    "# # print(search_results['artists']['items'][0]['popularity'])\n",
    "# # Extract relevant information from search results\n",
    "# artists = search_results['artists']['items']\n",
    "# data = []\n",
    "# for artist in artists:\n",
    "#     data.append({\n",
    "#         'name': artist['name'],\n",
    "#         'followers': artist['followers']['total'],\n",
    "#         'popularity': artist['popularity'],\n",
    "#         'genres': ', '.join(artist['genres']),\n",
    "#         'spotify_url': artist['external_urls']['spotify']\n",
    "#     })\n",
    "\n",
    "\n",
    "# # Create a DataFrame from the extracted data\n",
    "# df_artists = pd.DataFrame(data)\n",
    "# df_artists = df_artists.sort_values(by='popularity', ascending=False)\n",
    "# print(df_artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stubhub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "class StubhubProfile:\n",
    "    def __init__(self, artist, url = None, favourites = 0):\n",
    "        self.artist = artist\n",
    "        self.url =  url \n",
    "        self.favourites = favourites\n",
    "\n",
    "    def get_url(self):\n",
    "        if self.url:\n",
    "            return self.url\n",
    "        try:\n",
    "            pageSource = requests.get(\"https://www.stubhub.ca/secure/search?q=\" + self.artist).content\n",
    "        except:\n",
    "            pageSource = driver.get(\"https://www.stubhub.ca/secure/search?q=\" + self.artist).page_source\n",
    "        soup = BeautifulSoup(pageSource, 'html.parser')\n",
    "        script_tag = soup.find('script', {'id': 'index-data', 'type': 'application/json'})\n",
    "        json_data = json.loads(script_tag.string)\n",
    "        self.url = json_data['topSearchResults'][0]['url']\n",
    "        return self.url\n",
    "\n",
    "    def get_favourites(self):\n",
    "        if self.url is None:\n",
    "            return None\n",
    "        pageSource = requests.get(\"https://www.stubhub.ca/\" + self.url).content\n",
    "        soup = BeautifulSoup(pageSource, 'html.parser')\n",
    "        script_tag = soup.find('script', {'id': 'index-data', 'type': 'application/json'})\n",
    "        if script_tag is None:\n",
    "            return None\n",
    "        json_data = json.loads(script_tag.string)\n",
    "        if 'categorySummary' not in json_data:\n",
    "            return None\n",
    "        self.favourites = json_data['categorySummary']['aggregateFavorites']\n",
    "        return self.favourites\n",
    "\n",
    "    def get_all(self):\n",
    "        self.get_url()\n",
    "        self.get_favourites()\n",
    "        return self.url, self.favourites\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Artist: {self.artist}\\nURL: {self.url}\\nFavourites: {self.favourites}\"\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/illenium-tickets/performer/138422940', 980)\n",
      "Artist: illenium\n",
      "URL: /illenium-tickets/performer/138422940\n",
      "Favourites: 980\n"
     ]
    }
   ],
   "source": [
    "stubhub = StubhubProfile(\"illenium\")\n",
    "print(stubhub.get_all())\n",
    "print(stubhub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Social Media Profiles Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# Initialize a list to store the results\n",
    "\n",
    "# Iterate through each artist in the sales DataFrame\n",
    "for index, row in events.iterrows():\n",
    "    if artist in socials['artist'].values:\n",
    "        continue\n",
    "    \n",
    "    artist = row['Artist']\n",
    "    if any(result['artist'] == artist for result in results):\n",
    "        print(f\"Skipping {artist} as it is already processed.\")\n",
    "        continue\n",
    "\n",
    "    if artist in socials['Artist'].values:\n",
    "        print(f\"Skipping {artist} as it is already in sales.\")\n",
    "        continue\n",
    "    print(f\"Processing {artist}\")\n",
    "    instagram = InstagramProfile(artist)\n",
    "    spotify = SpotifyProfile(artist)\n",
    "    twitter = TwitterProfile(artist)\n",
    "    stubhub = StubhubProfile(artist)\n",
    "    instagram.get_all()\n",
    "    spotify.get_all()\n",
    "    twitter.get_all()\n",
    "    stubhub.get_all()\n",
    "    social = {\n",
    "        'artist': artist,\n",
    "        'instagram_username': instagram.username,\n",
    "        'instagram_followers': instagram.follower_count,\n",
    "        'spotify_id': spotify.spotifyID,\n",
    "        'spotify_genre': spotify.genre,\n",
    "        'spotify_followers': spotify.followers,\n",
    "        'spotify_popularity': spotify.popularity,\n",
    "        'spotify_listeners': spotify.listens,\n",
    "        'twitter_username': twitter.username,\n",
    "        'twitter_followers': twitter.follower_count,\n",
    "        'stubhub_url': stubhub.url,\n",
    "        'stubhub_favourites': stubhub.favourites\n",
    "    }\n",
    "    pprint.pprint(social)\n",
    "   \n",
    "    results.append(social)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "socials = pd.concat([socials, results_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(path, mode='a', engine=\"openpyxl\", if_sheet_exists=\"replace\") as writer:\n",
    "    socials.to_excel(writer, sheet_name=\"Socials\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
